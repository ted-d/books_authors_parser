import requests
from parsel import Selector

def fixed_blind_analysis():
    """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–ª–µ–ø–æ–π –∞–Ω–∞–ª–∏–∑ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏ —Ñ–∞–π–ª–æ–≤"""
    url = "https://quotes.toscrape.com/page/2/"
    
    try:
        response = requests.get(url)
        selector = Selector(response.text)
        
        print("üîç –ó–∞–ø—É—Å–∫–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–ª–µ–ø–æ–π –∞–Ω–∞–ª–∏–∑...")
        
        # 1. –ò—â–µ–º –í–°–ï —ç–ª–µ–º–µ–Ω—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º "life"
        life_elements = selector.xpath('//*[text()="life"]')
        print(f"üìå –ù–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å —Ç–µ–∫—Å—Ç–æ–º 'life': {len(life_elements)}")
        
        authors_data = []
        processed_containers = set()
        
        for life_element in life_elements:
            # 2. –ü–æ–¥–Ω–∏–º–∞–µ–º—Å—è –∫ –±–ª–∏–∂–∞–π—à–µ–º—É –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—É —Ü–∏—Ç–∞—Ç—ã
            quote_container = life_element.xpath('./ancestor::div[1]')
            
            if not quote_container:
                continue
                
            container = quote_container[0]
            container_html = container.get()
            
            if container_html in processed_containers:
                continue
            processed_containers.add(container_html)
            
            # 3. –ò—â–µ–º –∞–≤—Ç–æ—Ä–∞
            author = container.xpath('.//*[contains(@class, "author")]/text()').get()
            if not author:
                author = container.xpath('.//small/text()').get()
            
            # 4. –ò—â–µ–º —Ç–µ–∫—Å—Ç —Ü–∏—Ç–∞—Ç—ã
            quote_text = container.xpath('.//*[contains(@class, "text")]/text()').get()
            
            # 5. –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            if author:
                author = author.strip()
                if author.lower().startswith('by '):
                    author = author[3:].strip()
            
            if quote_text:
                quote_text = quote_text.strip('‚Äú‚Äù')
            
            # 6. –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –æ–±–∞ –ø–æ–ª—è
            if author and quote_text and len(author) > 3:
                authors_data.append({
                    'author': author,
                    'quote': quote_text,
                    'container_class': container.xpath('@class').get() or 'unknown',
                    'author_class': container.xpath('.//*[contains(@class, "author")]/@class').get() or 'unknown',
                    'text_class': container.xpath('.//*[contains(@class, "text")]/@class').get() or 'unknown'
                })
        
        # 7. –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_authors = []
        seen = set()
        for data in authors_data:
            key = (data['author'], data['quote'][:100])
            if key not in seen:
                seen.add(key)
                unique_authors.append(data)
        
        # 8. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –§–ò–ö–°–ò–†–û–í–ê–ù–ù–´–ï —Ñ–∞–π–ª—ã
        if unique_authors:
            # –§–∞–π–ª —Å –∞–≤—Ç–æ—Ä–∞–º–∏ (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º)
            with open('authors_with_life_tag.txt', 'w', encoding='utf-8') as f:
                for data in unique_authors:
                    f.write(f"–ê–≤—Ç–æ—Ä: {data['author']} | –¶–∏—Ç–∞—Ç–∞: {data['quote']}\n")
            
            # –§–∞–π–ª —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º–∏ (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º)
            with open('xpath_selectors_used.txt', 'w', encoding='utf-8') as f:
                f.write("XPath-–°–ï–õ–ï–ö–¢–û–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ù–´–ï –î–õ–Ø –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –î–ê–ù–ù–´–•:\n\n")
                f.write("–û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø–æ–∏—Å–∫–∞:\n")
                f.write("1. –ù–∞–π—Ç–∏ –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º 'life': //*[text()='life']\n")
                f.write("2. –ü–æ–¥–Ω—è—Ç—å—Å—è –∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—É: ./ancestor::div[1]\n")
                f.write("3. –ù–∞–π—Ç–∏ –∞–≤—Ç–æ—Ä–∞: .//*[contains(@class, 'author')]/text()\n")
                f.write("4. –ù–∞–π—Ç–∏ —Ü–∏—Ç–∞—Ç—É: .//*[contains(@class, 'text')]/text()\n\n")
                
                f.write("–û–ë–ù–ê–†–£–ñ–ï–ù–ù–´–ï –°–¢–†–£–ö–¢–£–†–´:\n")
                for i, data in enumerate(unique_authors, 1):
                    f.write(f"\n–ê–≤—Ç–æ—Ä {i}:\n")
                    f.write(f"  –ö–ª–∞—Å—Å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞: {data['container_class']}\n")
                    f.write(f"  –ö–ª–∞—Å—Å –∞–≤—Ç–æ—Ä–∞: {data['author_class']}\n")
                    f.write(f"  –ö–ª–∞—Å—Å —Ç–µ–∫—Å—Ç–∞: {data['text_class']}\n")
        
        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤: {len(unique_authors)}")
        for i, data in enumerate(unique_authors, 1):
            print(f"  {i}. {data['author']}")
            
        return unique_authors
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return []

def simple_and_reliable_method():
    """–ü—Ä–æ—Å—Ç–æ–π –∏ –Ω–∞–¥–µ–∂–Ω—ã–π –º–µ—Ç–æ–¥ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏ —Ñ–∞–π–ª–æ–≤"""
    url = "https://quotes.toscrape.com/page/2/"
    
    response = requests.get(url)
    selector = Selector(response.text)
    
    authors_data = []
    
    # –ò—â–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ —Å —Ç–µ–≥–æ–º "life"
    life_tags = selector.xpath('//a[text()="life"]')
    
    for tag in life_tags:
        # –ü–æ–¥–Ω–∏–º–∞–µ–º—Å—è –∫ div —Å –∫–ª–∞—Å—Å–æ–º quote
        quote_div = tag.xpath('./ancestor::div[contains(@class, "quote")]')
        
        if quote_div:
            author = quote_div.xpath('.//small[@class="author"]/text()').get()
            quote_text = quote_div.xpath('.//span[@class="text"]/text()').get()
            
            if author and quote_text:
                clean_quote = quote_text.strip('‚Äú‚Äù')
                authors_data.append(f"–ê–≤—Ç–æ—Ä: {author} | –¶–∏—Ç–∞—Ç–∞: {clean_quote}")
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    unique_data = list(set(authors_data))
    
    if unique_data:
        # –ü–ï–†–ï–ó–ê–ü–ò–°–´–í–ê–ï–ú —Ç–µ –∂–µ —Ñ–∞–π–ª—ã
        with open('authors_with_life_tag.txt', 'w', encoding='utf-8') as f:
            for data in unique_data:
                f.write(data + '\n')
        
        with open('xpath_selectors_used.txt', 'w', encoding='utf-8') as f:
            f.write("XPath-–°–ï–õ–ï–ö–¢–û–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ù–´–ï –î–õ–Ø –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –î–ê–ù–ù–´–•:\n\n")
            f.write("//a[text()='life']/ancestor::div[contains(@class, 'quote')] - –ø–æ–∏—Å–∫ —Ü–∏—Ç–∞—Ç —Å —Ç–µ–≥–æ–º 'life'\n")
            f.write(".//small[@class='author']/text() - –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–∞\n")
            f.write(".//span[@class='text']/text() - –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–∏—Ç–∞—Ç—ã\n")
    
    return unique_data

if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏...")
    
    # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥ (–Ω–∞–¥–µ–∂–Ω–µ–µ)
    result = simple_and_reliable_method()
    
    if result:
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ! –ù–∞–π–¥–µ–Ω–æ –∞–≤—Ç–æ—Ä–æ–≤: {len(result)}")
        print("üìÅ –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
        print("   - authors_with_life_tag.txt")
        print("   - xpath_selectors_used.txt")
        for i, data in enumerate(result, 1):
            print(f"  {i}. {data}")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ")