import requests
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor
import time
import re

def parse_single_page(page_num):
    """–ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å –º–µ—Ç–∫–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    base_url = "https://books.toscrape.com"
    
    if page_num == 1:
        url = f"{base_url}/catalogue/category/books_1/index.html"
    else:
        url = f"{base_url}/catalogue/category/books_1/page-{page_num}.html"
    
    try:
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')
        books = soup.find_all('article', class_='product_pod')
        
        page_data = []
        for book in books:
            try:
                title = book.find('h3').find('a')['title']
                price = book.find('p', class_='price_color').get_text().strip()
                relative_link = book.find('h3').find('a')['href']
                
                # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Å—ã–ª–∫–∏
                if relative_link.startswith('../../../'):
                    # –£–±–∏—Ä–∞–µ–º –≤—Å–µ ../ –∏ –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–Ω–µ—á–Ω—ã–π –ø—É—Ç—å
                    clean_link = re.sub(r'\.\./', '', relative_link)
                    link = base_url + '/catalogue/' + clean_link
                elif relative_link.startswith('../../'):
                    clean_link = re.sub(r'\.\./', '', relative_link)
                    link = base_url + '/catalogue/' + clean_link
                else:
                    link = base_url + '/catalogue/' + relative_link
                
                # –£–±–µ–¥–∏–º—Å—è —á—Ç–æ —Å—Å—ã–ª–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è
                link = link.replace('//catalogue', '/catalogue')
                
                page_data.append({
                    'page': page_num,
                    'title': title,
                    'price': price,
                    'link': link
                })
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∫–Ω–∏–≥–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}: {e}")
                continue
        
        print(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: {len(page_data)} –∫–Ω–∏–≥")
        return page_data
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {e}")
        return []

def main():
    print("üöÄ –ó–ê–ü–£–°–ö –ü–ê–†–°–ï–†–ê –° –ü–†–ê–í–ò–õ–¨–ù–´–ú–ò –°–°–´–õ–ö–ê–ú–ò")
    start_time = time.time()
    
    total_pages = 50
    all_books_data = []
    
    # –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—ã–π —Å–±–æ—Ä
    with ThreadPoolExecutor(max_workers=10) as executor:
        results = list(executor.map(parse_single_page, range(1, total_pages + 1)))
    
    # –°–æ–±–∏—Ä–∞–µ–º –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
    for page_data in results:
        all_books_data.extend(page_data)
    
    all_books_data.sort(key=lambda x: x['page'])
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º
    with open('books_data.txt', 'w', encoding='utf-8') as f:
        for book in all_books_data:
            f.write(f"{book['title']}|–¶–µ–Ω–∞: {book['price']}|{book['link']}\n")


    
    print(f"\nüéØ –°–æ–±—Ä–∞–Ω–æ {len(all_books_data)} –∫–Ω–∏–≥ –∑–∞ {time.time()-start_time:.2f} —Å–µ–∫")
    print("üìÅ –§–∞–π–ª: books_data.txt")

if __name__ == "__main__":
    main()